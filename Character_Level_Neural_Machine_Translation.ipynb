{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175623"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "lines = pd.read_csv('fra.txt', names = ['src','tar','cc'], sep='\\t')\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54943</th>\n",
       "      <td>I think about Tom often.</td>\n",
       "      <td>Je pense souvent à Tom.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43980</th>\n",
       "      <td>They are the same age.</td>\n",
       "      <td>Ils ont le même âge.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15625</th>\n",
       "      <td>It's worth a try.</td>\n",
       "      <td>Ça vaut le coup d'être essayé.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>I want to resign.</td>\n",
       "      <td>Je veux démissionner.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20084</th>\n",
       "      <td>It's the only way.</td>\n",
       "      <td>C'est la seule façon.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59600</th>\n",
       "      <td>Do you feel like resting?</td>\n",
       "      <td>Veux-tu te reposer ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23799</th>\n",
       "      <td>I don't understand.</td>\n",
       "      <td>Je ne comprends pas.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8178</th>\n",
       "      <td>I want a puppy.</td>\n",
       "      <td>Je veux un petit chien.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23389</th>\n",
       "      <td>He took a big risk.</td>\n",
       "      <td>Il a pris un gros risque.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16022</th>\n",
       "      <td>She rode a camel.</td>\n",
       "      <td>Elle est montée sur un chameau.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             src                              tar\n",
       "54943   I think about Tom often.          Je pense souvent à Tom.\n",
       "43980     They are the same age.             Ils ont le même âge.\n",
       "15625          It's worth a try.   Ça vaut le coup d'être essayé.\n",
       "14997          I want to resign.            Je veux démissionner.\n",
       "20084         It's the only way.            C'est la seule façon.\n",
       "59600  Do you feel like resting?             Veux-tu te reposer ?\n",
       "23799        I don't understand.             Je ne comprends pas.\n",
       "8178             I want a puppy.          Je veux un petit chien.\n",
       "23389        He took a big risk.        Il a pris un gros risque.\n",
       "16022          She rode a camel.  Elle est montée sur un chameau."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines.drop(['cc'], axis = 1)\n",
    "lines = lines[0:60000]\n",
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28368</th>\n",
       "      <td>Give the keys to me.</td>\n",
       "      <td>\\t Donne-moi les clés. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14690</th>\n",
       "      <td>I knit every day.</td>\n",
       "      <td>\\t Je tricote tous les jours. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33432</th>\n",
       "      <td>Can I come backstage?</td>\n",
       "      <td>\\t Puis-je venir dans les coulisses? \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28815</th>\n",
       "      <td>How did that happen?</td>\n",
       "      <td>\\t Comment est-ce arrivé ? \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10015</th>\n",
       "      <td>Boy was I wrong.</td>\n",
       "      <td>\\t Combien j'avais tort ! \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40915</th>\n",
       "      <td>I also wanted to know.</td>\n",
       "      <td>\\t Je voulais aussi savoir. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22077</th>\n",
       "      <td>You came too late.</td>\n",
       "      <td>\\t Vous êtes venu trop tard. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40152</th>\n",
       "      <td>Don't let the cat out.</td>\n",
       "      <td>\\t Ne laissez pas sortir le chat. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13127</th>\n",
       "      <td>You almost died.</td>\n",
       "      <td>\\t Vous êtes presque mort. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12126</th>\n",
       "      <td>She never reads.</td>\n",
       "      <td>\\t Elle ne lit jamais. \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          src                                      tar\n",
       "28368    Give the keys to me.                \\t Donne-moi les clés. \\n\n",
       "14690       I knit every day.         \\t Je tricote tous les jours. \\n\n",
       "33432   Can I come backstage?  \\t Puis-je venir dans les coulisses? \\n\n",
       "28815    How did that happen?            \\t Comment est-ce arrivé ? \\n\n",
       "10015        Boy was I wrong.             \\t Combien j'avais tort ! \\n\n",
       "40915  I also wanted to know.           \\t Je voulais aussi savoir. \\n\n",
       "22077      You came too late.          \\t Vous êtes venu trop tard. \\n\n",
       "40152  Don't let the cat out.     \\t Ne laissez pas sortir le chat. \\n\n",
       "13127        You almost died.            \\t Vous êtes presque mort. \\n\n",
       "12126        She never reads.                \\t Elle ne lit jamais. \\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.tar = lines.tar.apply(lambda x : '\\t ' + x + ' \\n')\n",
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = set()\n",
    "for line in lines.src:\n",
    "    for char in line:\n",
    "        src_vocab.add(char)\n",
    "\n",
    "tar_vocab = set()\n",
    "for line in lines.tar:\n",
    "    for char in line:\n",
    "        tar_vocab.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n",
      "106\n"
     ]
    }
   ],
   "source": [
    "src_vocab_size = len(src_vocab)+1\n",
    "tar_vocab_size = len(tar_vocab)+1\n",
    "print(src_vocab_size)\n",
    "print(tar_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "['T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w']\n"
     ]
    }
   ],
   "source": [
    "src_vocab = sorted(list(src_vocab))\n",
    "tar_vocab = sorted(list(tar_vocab))\n",
    "print(src_vocab[45:75])\n",
    "print(tar_vocab[45:75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 1, '!': 2, '\"': 3, '$': 4, '%': 5, '&': 6, \"'\": 7, ',': 8, '-': 9, '.': 10, '/': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ':': 22, '?': 23, 'A': 24, 'B': 25, 'C': 26, 'D': 27, 'E': 28, 'F': 29, 'G': 30, 'H': 31, 'I': 32, 'J': 33, 'K': 34, 'L': 35, 'M': 36, 'N': 37, 'O': 38, 'P': 39, 'Q': 40, 'R': 41, 'S': 42, 'T': 43, 'U': 44, 'V': 45, 'W': 46, 'X': 47, 'Y': 48, 'Z': 49, 'a': 50, 'b': 51, 'c': 52, 'd': 53, 'e': 54, 'f': 55, 'g': 56, 'h': 57, 'i': 58, 'j': 59, 'k': 60, 'l': 61, 'm': 62, 'n': 63, 'o': 64, 'p': 65, 'q': 66, 'r': 67, 's': 68, 't': 69, 'u': 70, 'v': 71, 'w': 72, 'x': 73, 'y': 74, 'z': 75, 'é': 76, '’': 77, '€': 78}\n",
      "{'\\t': 1, '\\n': 2, ' ': 3, '!': 4, '\"': 5, '$': 6, '%': 7, '&': 8, \"'\": 9, '(': 10, ')': 11, ',': 12, '-': 13, '.': 14, '0': 15, '1': 16, '2': 17, '3': 18, '4': 19, '5': 20, '6': 21, '7': 22, '8': 23, '9': 24, ':': 25, '?': 26, 'A': 27, 'B': 28, 'C': 29, 'D': 30, 'E': 31, 'F': 32, 'G': 33, 'H': 34, 'I': 35, 'J': 36, 'K': 37, 'L': 38, 'M': 39, 'N': 40, 'O': 41, 'P': 42, 'Q': 43, 'R': 44, 'S': 45, 'T': 46, 'U': 47, 'V': 48, 'W': 49, 'X': 50, 'Y': 51, 'Z': 52, 'a': 53, 'b': 54, 'c': 55, 'd': 56, 'e': 57, 'f': 58, 'g': 59, 'h': 60, 'i': 61, 'j': 62, 'k': 63, 'l': 64, 'm': 65, 'n': 66, 'o': 67, 'p': 68, 'q': 69, 'r': 70, 's': 71, 't': 72, 'u': 73, 'v': 74, 'w': 75, 'x': 76, 'y': 77, 'z': 78, '\\xa0': 79, '«': 80, '»': 81, 'À': 82, 'Ç': 83, 'É': 84, 'Ê': 85, 'Ô': 86, 'à': 87, 'â': 88, 'ç': 89, 'è': 90, 'é': 91, 'ê': 92, 'ë': 93, 'î': 94, 'ï': 95, 'ô': 96, 'ù': 97, 'û': 98, 'œ': 99, 'С': 100, '\\u2009': 101, '\\u200b': 102, '‘': 103, '’': 104, '\\u202f': 105}\n"
     ]
    }
   ],
   "source": [
    "src_to_index = dict([(word, i+1) for i, word in enumerate(src_vocab)])\n",
    "tar_to_index = dict([(word, i+1) for i, word in enumerate(tar_vocab)])\n",
    "print(src_to_index)\n",
    "print(tar_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30, 64, 10], [31, 58, 10], [31, 58, 10], [41, 70, 63, 2], [41, 70, 63, 2]]\n"
     ]
    }
   ],
   "source": [
    "encoder_input = []\n",
    "for line in lines.src:\n",
    "    temp_X = []\n",
    "    for w in line:\n",
    "        temp_X.append(src_to_index[w])\n",
    "    encoder_input.append(temp_X)\n",
    "print(encoder_input[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 48, 53, 3, 4, 3, 2], [1, 3, 45, 53, 64, 73, 72, 3, 4, 3, 2], [1, 3, 45, 53, 64, 73, 72, 14, 3, 2], [1, 3, 29, 67, 73, 70, 71, 105, 4, 3, 2], [1, 3, 29, 67, 73, 70, 57, 78, 105, 4, 3, 2]]\n"
     ]
    }
   ],
   "source": [
    "decoder_input = []\n",
    "for line in lines.tar:\n",
    "    temp_X = []\n",
    "    for w in line:\n",
    "        temp_X.append(tar_to_index[w])\n",
    "    decoder_input.append(temp_X)\n",
    "print(decoder_input[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 48, 53, 3, 4, 3, 2], [3, 45, 53, 64, 73, 72, 3, 4, 3, 2], [3, 45, 53, 64, 73, 72, 14, 3, 2], [3, 29, 67, 73, 70, 71, 105, 4, 3, 2], [3, 29, 67, 73, 70, 57, 78, 105, 4, 3, 2]]\n"
     ]
    }
   ],
   "source": [
    "decoder_target = []\n",
    "for line in lines.tar:\n",
    "    t = 0\n",
    "    temp_X = []\n",
    "    for w in line:\n",
    "        if t > 0 :\n",
    "            temp_X.append(tar_to_index[w])\n",
    "        t = t + 1\n",
    "    decoder_target.append(temp_X)\n",
    "print(decoder_target[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "76\n"
     ]
    }
   ],
   "source": [
    "max_src_len = max([len(line) for line in lines.src])\n",
    "max_tar_len = max([len(line) for line in lines.tar])\n",
    "print(max_src_len)\n",
    "print(max_tar_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "encoder_input = pad_sequences(encoder_input, maxlen=max_src_len, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen=max_tar_len, padding='post')\n",
    "decoder_target= pad_sequences(decoder_target, maxlen=max_tar_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "encoder_input = to_categorical(encoder_input)\n",
    "decoder_input = to_categorical(decoder_input)\n",
    "decoder_target = to_categorical(decoder_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teacher Forcing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "디코더에서 이전 셀의 예측 결과를 다음 단계에 인풋으로 넣는 것이 아니라 이전 셀의 실제 값을 다음 단계에 인풋으로 넣어 학습의 정확도를 높여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## seq2seq 기계 번역기 훈련시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0516 02:30:06.403816 24428 deprecation.py:506] From c:\\users\\yunja_kuj61s9\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "encoder_inputs = Input(shape=(None, src_vocab_size))\n",
    "encoder_lstm = LSTM(units=256, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, tar_vocab_size))\n",
    "decoder_lstm = LSTM(units=256, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _=decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "\n",
    "decoder_softmax_layer = Dense(tar_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0516 02:59:14.438089 24428 deprecation.py:323] From c:\\users\\yunja_kuj61s9\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "48000/48000 [==============================] - 513s 11ms/sample - loss: 0.7837 - val_loss: 0.6701\n",
      "Epoch 2/50\n",
      "48000/48000 [==============================] - 524s 11ms/sample - loss: 0.4771 - val_loss: 0.5472\n",
      "Epoch 3/50\n",
      "48000/48000 [==============================] - 524s 11ms/sample - loss: 0.3930 - val_loss: 0.4818\n",
      "Epoch 4/50\n",
      "48000/48000 [==============================] - 532s 11ms/sample - loss: 0.3481 - val_loss: 0.4442\n",
      "Epoch 5/50\n",
      "48000/48000 [==============================] - 537s 11ms/sample - loss: 0.3194 - val_loss: 0.4177\n",
      "Epoch 6/50\n",
      "48000/48000 [==============================] - 539s 11ms/sample - loss: 0.2986 - val_loss: 0.4025\n",
      "Epoch 7/50\n",
      "48000/48000 [==============================] - 550s 11ms/sample - loss: 0.2828 - val_loss: 0.3935\n",
      "Epoch 8/50\n",
      "48000/48000 [==============================] - 551s 11ms/sample - loss: 0.2698 - val_loss: 0.3835\n",
      "Epoch 9/50\n",
      "48000/48000 [==============================] - 545s 11ms/sample - loss: 0.2589 - val_loss: 0.3758\n",
      "Epoch 10/50\n",
      "48000/48000 [==============================] - 541s 11ms/sample - loss: 0.2497 - val_loss: 0.3718\n",
      "Epoch 11/50\n",
      "48000/48000 [==============================] - 543s 11ms/sample - loss: 0.2414 - val_loss: 0.3687\n",
      "Epoch 12/50\n",
      "48000/48000 [==============================] - 568s 12ms/sample - loss: 0.2340 - val_loss: 0.3639\n",
      "Epoch 13/50\n",
      "48000/48000 [==============================] - 542s 11ms/sample - loss: 0.2275 - val_loss: 0.3622\n",
      "Epoch 14/50\n",
      "48000/48000 [==============================] - 543s 11ms/sample - loss: 0.2215 - val_loss: 0.3605\n",
      "Epoch 15/50\n",
      "48000/48000 [==============================] - 535s 11ms/sample - loss: 0.2160 - val_loss: 0.3603\n",
      "Epoch 16/50\n",
      "48000/48000 [==============================] - 543s 11ms/sample - loss: 0.2109 - val_loss: 0.3588\n",
      "Epoch 17/50\n",
      "48000/48000 [==============================] - 541s 11ms/sample - loss: 0.2063 - val_loss: 0.3613\n",
      "Epoch 18/50\n",
      "48000/48000 [==============================] - 544s 11ms/sample - loss: 0.2018 - val_loss: 0.3607\n",
      "Epoch 19/50\n",
      "48000/48000 [==============================] - 539s 11ms/sample - loss: 0.1977 - val_loss: 0.3616\n",
      "Epoch 20/50\n",
      "48000/48000 [==============================] - 543s 11ms/sample - loss: 0.1937 - val_loss: 0.3620\n",
      "Epoch 21/50\n",
      "48000/48000 [==============================] - 548s 11ms/sample - loss: 0.1901 - val_loss: 0.3618\n",
      "Epoch 22/50\n",
      "48000/48000 [==============================] - 2936s 61ms/sample - loss: 0.1866 - val_loss: 0.3644\n",
      "Epoch 23/50\n",
      "48000/48000 [==============================] - 23987s 500ms/sample - loss: 0.1833 - val_loss: 0.3659\n",
      "Epoch 24/50\n",
      "48000/48000 [==============================] - 520s 11ms/sample - loss: 0.1802 - val_loss: 0.3684\n",
      "Epoch 25/50\n",
      "48000/48000 [==============================] - 550s 11ms/sample - loss: 0.1772 - val_loss: 0.3693\n",
      "Epoch 26/50\n",
      "48000/48000 [==============================] - 522s 11ms/sample - loss: 0.1743 - val_loss: 0.3722\n",
      "Epoch 27/50\n",
      "48000/48000 [==============================] - 524s 11ms/sample - loss: 0.1716 - val_loss: 0.3739\n",
      "Epoch 28/50\n",
      "48000/48000 [==============================] - 523s 11ms/sample - loss: 0.1690 - val_loss: 0.3760\n",
      "Epoch 29/50\n",
      "48000/48000 [==============================] - 596s 12ms/sample - loss: 0.1664 - val_loss: 0.3775\n",
      "Epoch 30/50\n",
      "48000/48000 [==============================] - 702s 15ms/sample - loss: 0.1642 - val_loss: 0.3803\n",
      "Epoch 31/50\n",
      "48000/48000 [==============================] - 686s 14ms/sample - loss: 0.1619 - val_loss: 0.3837\n",
      "Epoch 32/50\n",
      "48000/48000 [==============================] - 686s 14ms/sample - loss: 0.1597 - val_loss: 0.3839\n",
      "Epoch 33/50\n",
      "48000/48000 [==============================] - 702s 15ms/sample - loss: 0.1577 - val_loss: 0.3886\n",
      "Epoch 34/50\n",
      "48000/48000 [==============================] - 694s 14ms/sample - loss: 0.1556 - val_loss: 0.3914\n",
      "Epoch 35/50\n",
      "48000/48000 [==============================] - 629s 13ms/sample - loss: 0.1537 - val_loss: 0.3920\n",
      "Epoch 36/50\n",
      "48000/48000 [==============================] - 560s 12ms/sample - loss: 0.1517 - val_loss: 0.3949\n",
      "Epoch 37/50\n",
      "48000/48000 [==============================] - 572s 12ms/sample - loss: 0.1500 - val_loss: 0.3966\n",
      "Epoch 38/50\n",
      "48000/48000 [==============================] - 589s 12ms/sample - loss: 0.1483 - val_loss: 0.3987\n",
      "Epoch 39/50\n",
      "48000/48000 [==============================] - 592s 12ms/sample - loss: 0.1465 - val_loss: 0.4007\n",
      "Epoch 40/50\n",
      "48000/48000 [==============================] - 567s 12ms/sample - loss: 0.1450 - val_loss: 0.4033\n",
      "Epoch 41/50\n",
      "48000/48000 [==============================] - 594s 12ms/sample - loss: 0.1432 - val_loss: 0.4080\n",
      "Epoch 42/50\n",
      "48000/48000 [==============================] - 564s 12ms/sample - loss: 0.1418 - val_loss: 0.4089\n",
      "Epoch 43/50\n",
      "48000/48000 [==============================] - 605s 13ms/sample - loss: 0.1403 - val_loss: 0.4114\n",
      "Epoch 44/50\n",
      "48000/48000 [==============================] - 589s 12ms/sample - loss: 0.1390 - val_loss: 0.4155\n",
      "Epoch 45/50\n",
      "48000/48000 [==============================] - 586s 12ms/sample - loss: 0.1376 - val_loss: 0.4184\n",
      "Epoch 46/50\n",
      "48000/48000 [==============================] - 581s 12ms/sample - loss: 0.1363 - val_loss: 0.4193\n",
      "Epoch 47/50\n",
      "48000/48000 [==============================] - 580s 12ms/sample - loss: 0.1349 - val_loss: 0.4222\n",
      "Epoch 48/50\n",
      "48000/48000 [==============================] - 577s 12ms/sample - loss: 0.1338 - val_loss: 0.4232\n",
      "Epoch 49/50\n",
      "48000/48000 [==============================] - 576s 12ms/sample - loss: 0.1327 - val_loss: 0.4246\n",
      "Epoch 50/50\n",
      "48000/48000 [==============================] - 576s 12ms/sample - loss: 0.1312 - val_loss: 0.4272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24f99892cf8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[encoder_input, decoder_input], y=decoder_target, batch_size=64, epochs=50, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(inputs = encoder_inputs, outputs = encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(256,))\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, \n",
    "                                                 initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "decoder_model = Model(inputs = [decoder_inputs] + decoder_states_inputs, \n",
    "                      outputs = [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_src = dict((i,char) for char, i in src_to_index.items())\n",
    "index_to_tar = dict((i,char) for char, i in tar_to_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1,1,tar_vocab_size))\n",
    "    target_seq[0,0,tar_to_index['\\t']] = 1.\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "    \n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        \n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = index_to_tar[sampled_token_index]\n",
    "        \n",
    "        decoded_sentence += sampled_char\n",
    "        \n",
    "        if(sampled_char == '\\n' or len(decoded_sentence) > max_tar_len):\n",
    "            stop_condition = True\n",
    "            \n",
    "        target_seq = np.zeros((1,1,tar_vocab_size))\n",
    "        target_seq[0,0,sampled_token_index] = 1.\n",
    "        \n",
    "        states_value = [h, c]\n",
    "        \n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "입력 문장: Run!\n",
      "정답 문장:  Cours ! \n",
      "번역기가 번역한 문장:  Cours ! \n",
      "-----------------------------------\n",
      "입력 문장: I lied.\n",
      "정답 문장:  J'ai menti. \n",
      "번역기가 번역한 문장:  J'ai pris un seut-ce. \n",
      "-----------------------------------\n",
      "입력 문장: Come in.\n",
      "정답 문장:  Entre. \n",
      "번역기가 번역한 문장:  Entrez ! \n",
      "-----------------------------------\n",
      "입력 문장: I did OK.\n",
      "정답 문장:  Je m'en suis bien sortie. \n",
      "번역기가 번역한 문장:  Je m'en suis bien sorti. \n",
      "-----------------------------------\n",
      "입력 문장: We're sad.\n",
      "정답 문장:  Nous sommes tristes. \n",
      "번역기가 번역한 문장:  Nous sommes bourrés. \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for seq_index in [3, 50, 100, 300, 1001]:\n",
    "    input_seq = encoder_input[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(35 * \"-\")\n",
    "    print('입력 문장:', lines.src[seq_index])\n",
    "    print('정답 문장:', lines.tar[seq_index][1:len(lines.tar[seq_index])-1])\n",
    "    print('번역기가 번역한 문장:', decoded_sentence[:len(decoded_sentence)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 문장: I want a cat.\n",
      "번역기가 번역한 문장:  Je veux une nouvelle voiture. \n"
     ]
    }
   ],
   "source": [
    "sent = ['I want a cat.']\n",
    "input_sent = []\n",
    "for line in sent:\n",
    "    for w in line:\n",
    "        input_sent.append(src_to_index[w])\n",
    "input_sent = pad_sequences([input_sent], maxlen=max_src_len, padding='post')\n",
    "inputSent = to_categorical(input_sent, 79)\n",
    "decoded_sent = decode_sequence(inputSent)\n",
    "print('입력 문장: '+sent[0])\n",
    "print('번역기가 번역한 문장:', decoded_sent[:len(decoded_sent)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
