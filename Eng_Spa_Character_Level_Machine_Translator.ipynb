{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123770"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "lines = pd.read_csv('spa.txt', names = ['src','tar','cc'], sep = '\\t')\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.utils import shuffle\n",
    "#lines = shuffle(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79485</th>\n",
       "      <td>I have to fix the washing machine.</td>\n",
       "      <td>Tengo que arreglar la lavadora.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52611</th>\n",
       "      <td>Tom climbed over the fence.</td>\n",
       "      <td>Tom trepó por encima de la cerca.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88172</th>\n",
       "      <td>You can put your name on a name tag.</td>\n",
       "      <td>Puedes poner tu nombre en una etiqueta.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64400</th>\n",
       "      <td>Japanese is our mother tongue.</td>\n",
       "      <td>El japonés es nuestra lengua materna.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75877</th>\n",
       "      <td>I never doubted you for a moment.</td>\n",
       "      <td>Nunca dudé de ti ni por un momento.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80311</th>\n",
       "      <td>My apartment is not far from here.</td>\n",
       "      <td>Mi departamento no queda lejos de aquí.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76232</th>\n",
       "      <td>I'm getting used to this weather.</td>\n",
       "      <td>Me estoy acostumbrando a este clima.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93074</th>\n",
       "      <td>Tom didn't seem too surprised, either.</td>\n",
       "      <td>Tom no parecía demasiado soprendido, tampoco.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56934</th>\n",
       "      <td>Tom always speaks in French.</td>\n",
       "      <td>Tom siempre habla francés.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66295</th>\n",
       "      <td>Why is everyone looking at me?</td>\n",
       "      <td>¿Por qué me mira todo el mundo?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          src  \\\n",
       "79485      I have to fix the washing machine.   \n",
       "52611             Tom climbed over the fence.   \n",
       "88172    You can put your name on a name tag.   \n",
       "64400          Japanese is our mother tongue.   \n",
       "75877       I never doubted you for a moment.   \n",
       "80311      My apartment is not far from here.   \n",
       "76232       I'm getting used to this weather.   \n",
       "93074  Tom didn't seem too surprised, either.   \n",
       "56934            Tom always speaks in French.   \n",
       "66295          Why is everyone looking at me?   \n",
       "\n",
       "                                                 tar  \n",
       "79485                Tengo que arreglar la lavadora.  \n",
       "52611              Tom trepó por encima de la cerca.  \n",
       "88172        Puedes poner tu nombre en una etiqueta.  \n",
       "64400          El japonés es nuestra lengua materna.  \n",
       "75877            Nunca dudé de ti ni por un momento.  \n",
       "80311        Mi departamento no queda lejos de aquí.  \n",
       "76232           Me estoy acostumbrando a este clima.  \n",
       "93074  Tom no parecía demasiado soprendido, tampoco.  \n",
       "56934                     Tom siempre habla francés.  \n",
       "66295                ¿Por qué me mira todo el mundo?  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines.drop(['cc'], axis = 1)\n",
    "lines = lines[50000:100000]\n",
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87437</th>\n",
       "      <td>This is a good learning environment.</td>\n",
       "      <td>\\t Este es un buen entorno de aprendizaje. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71902</th>\n",
       "      <td>I just wanted to make you proud.</td>\n",
       "      <td>\\t Solo quería enorgullecerlos. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82236</th>\n",
       "      <td>Do you like to live in the country?</td>\n",
       "      <td>\\t ¿Le gusta vivir en el campo? \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54834</th>\n",
       "      <td>I don't know either of them.</td>\n",
       "      <td>\\t No conozco a ninguno de los dos. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60165</th>\n",
       "      <td>I've read all kinds of books.</td>\n",
       "      <td>\\t He leído toda clase de libros. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79798</th>\n",
       "      <td>I want to talk privately with Tom.</td>\n",
       "      <td>\\t Quiero hablar con Tom en privado. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72941</th>\n",
       "      <td>Running is good for your health.</td>\n",
       "      <td>\\t Correr es bueno para la salud. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58999</th>\n",
       "      <td>He's accustomed to traveling.</td>\n",
       "      <td>\\t Él está acostumbrado a viajar. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72775</th>\n",
       "      <td>My aunt brought me some flowers.</td>\n",
       "      <td>\\t Mi tía me trajo algunas flores. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92532</th>\n",
       "      <td>She baked bread and cakes in the oven.</td>\n",
       "      <td>\\t Ella cocinó pan y bizcochuelos en el horno. \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          src  \\\n",
       "87437    This is a good learning environment.   \n",
       "71902        I just wanted to make you proud.   \n",
       "82236     Do you like to live in the country?   \n",
       "54834            I don't know either of them.   \n",
       "60165           I've read all kinds of books.   \n",
       "79798      I want to talk privately with Tom.   \n",
       "72941        Running is good for your health.   \n",
       "58999           He's accustomed to traveling.   \n",
       "72775        My aunt brought me some flowers.   \n",
       "92532  She baked bread and cakes in the oven.   \n",
       "\n",
       "                                                     tar  \n",
       "87437      \\t Este es un buen entorno de aprendizaje. \\n  \n",
       "71902                 \\t Solo quería enorgullecerlos. \\n  \n",
       "82236                 \\t ¿Le gusta vivir en el campo? \\n  \n",
       "54834             \\t No conozco a ninguno de los dos. \\n  \n",
       "60165               \\t He leído toda clase de libros. \\n  \n",
       "79798            \\t Quiero hablar con Tom en privado. \\n  \n",
       "72941               \\t Correr es bueno para la salud. \\n  \n",
       "58999               \\t Él está acostumbrado a viajar. \\n  \n",
       "72775              \\t Mi tía me trajo algunas flores. \\n  \n",
       "92532  \\t Ella cocinó pan y bizcochuelos en el horno. \\n  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.tar = lines.tar.apply(lambda x : '\\t ' + x + ' \\n')\n",
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = set()\n",
    "for line in lines.src:\n",
    "    for char in line:\n",
    "        src_vocab.add(char)\n",
    "\n",
    "tar_vocab = set()\n",
    "for line in lines.tar:\n",
    "    for char in line:\n",
    "        tar_vocab.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "src_vocab_size = len(src_vocab)+1\n",
    "tar_vocab_size = len(tar_vocab)+1\n",
    "print(src_vocab_size)\n",
    "print(tar_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '°']\n",
      "['T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w']\n"
     ]
    }
   ],
   "source": [
    "src_vocab = sorted(list(src_vocab))\n",
    "tar_vocab = sorted(list(tar_vocab))\n",
    "print(src_vocab[45:75])\n",
    "print(tar_vocab[45:75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 1, '!': 2, '\"': 3, '$': 4, '%': 5, \"'\": 6, ',': 7, '-': 8, '.': 9, '0': 10, '1': 11, '2': 12, '3': 13, '4': 14, '5': 15, '6': 16, '7': 17, '8': 18, '9': 19, ':': 20, ';': 21, '?': 22, 'A': 23, 'B': 24, 'C': 25, 'D': 26, 'E': 27, 'F': 28, 'G': 29, 'H': 30, 'I': 31, 'J': 32, 'K': 33, 'L': 34, 'M': 35, 'N': 36, 'O': 37, 'P': 38, 'Q': 39, 'R': 40, 'S': 41, 'T': 42, 'U': 43, 'V': 44, 'W': 45, 'X': 46, 'Y': 47, 'Z': 48, 'a': 49, 'b': 50, 'c': 51, 'd': 52, 'e': 53, 'f': 54, 'g': 55, 'h': 56, 'i': 57, 'j': 58, 'k': 59, 'l': 60, 'm': 61, 'n': 62, 'o': 63, 'p': 64, 'q': 65, 'r': 66, 's': 67, 't': 68, 'u': 69, 'v': 70, 'w': 71, 'x': 72, 'y': 73, 'z': 74, '°': 75, 'á': 76, 'ã': 77, 'è': 78, 'é': 79, 'ö': 80, '‘': 81, '’': 82, '₂': 83}\n",
      "{'\\t': 1, '\\n': 2, ' ': 3, '!': 4, '\"': 5, '$': 6, '%': 7, \"'\": 8, '(': 9, ')': 10, ',': 11, '-': 12, '.': 13, '0': 14, '1': 15, '2': 16, '3': 17, '4': 18, '5': 19, '6': 20, '7': 21, '8': 22, '9': 23, ':': 24, ';': 25, '?': 26, 'A': 27, 'B': 28, 'C': 29, 'D': 30, 'E': 31, 'F': 32, 'G': 33, 'H': 34, 'I': 35, 'J': 36, 'K': 37, 'L': 38, 'M': 39, 'N': 40, 'O': 41, 'P': 42, 'Q': 43, 'R': 44, 'S': 45, 'T': 46, 'U': 47, 'V': 48, 'W': 49, 'X': 50, 'Y': 51, 'Z': 52, 'a': 53, 'b': 54, 'c': 55, 'd': 56, 'e': 57, 'f': 58, 'g': 59, 'h': 60, 'i': 61, 'j': 62, 'k': 63, 'l': 64, 'm': 65, 'n': 66, 'o': 67, 'p': 68, 'q': 69, 'r': 70, 's': 71, 't': 72, 'u': 73, 'v': 74, 'w': 75, 'x': 76, 'y': 77, 'z': 78, '¡': 79, '«': 80, 'º': 81, '»': 82, '¿': 83, 'Á': 84, 'É': 85, 'Ú': 86, 'á': 87, 'è': 88, 'é': 89, 'í': 90, 'ñ': 91, 'ó': 92, 'ö': 93, 'ú': 94, 'ü': 95, 'ś': 96, '\\u200b': 97, '—': 98}\n"
     ]
    }
   ],
   "source": [
    "src_to_index = dict([(word, i+1) for i, word in enumerate(src_vocab)])\n",
    "tar_to_index = dict([(word, i+1) for i, word in enumerate(tar_vocab)])\n",
    "print(src_to_index)\n",
    "print(tar_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28, 57, 60, 60, 1, 63, 69, 68, 1, 68, 56, 57, 67, 1, 54, 63, 66, 61, 7, 1, 64, 60, 53, 49, 67, 53, 9], [28, 57, 60, 60, 1, 68, 56, 53, 1, 50, 69, 51, 59, 53, 68, 1, 71, 57, 68, 56, 1, 71, 49, 68, 53, 66, 9], [28, 57, 62, 49, 60, 60, 73, 7, 1, 31, 1, 56, 49, 70, 53, 1, 61, 73, 1, 63, 71, 62, 1, 51, 49, 66, 9], [28, 57, 62, 49, 60, 60, 73, 7, 1, 31, 1, 56, 49, 70, 53, 1, 61, 73, 1, 63, 71, 62, 1, 51, 49, 66, 9], [28, 57, 66, 67, 68, 7, 1, 60, 53, 68, 1, 61, 53, 1, 49, 67, 59, 1, 73, 63, 69, 1, 68, 56, 57, 67, 9]]\n"
     ]
    }
   ],
   "source": [
    "encoder_input = []\n",
    "for line in lines.src:\n",
    "    temp_X = []\n",
    "    for w in line:\n",
    "        temp_X.append(src_to_index[w])\n",
    "    encoder_input.append(temp_X)\n",
    "print(encoder_input[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 44, 57, 64, 64, 57, 66, 57, 3, 57, 71, 72, 57, 3, 58, 67, 70, 65, 73, 64, 53, 70, 61, 67, 11, 3, 68, 67, 70, 3, 58, 53, 74, 67, 70, 13, 3, 2], [1, 3, 38, 64, 57, 66, 53, 3, 57, 64, 3, 54, 53, 64, 56, 57, 3, 55, 67, 66, 3, 53, 59, 73, 53, 13, 3, 2], [1, 3, 32, 61, 66, 53, 64, 65, 57, 66, 72, 57, 3, 72, 57, 66, 59, 67, 3, 65, 61, 3, 68, 70, 67, 68, 61, 67, 3, 53, 73, 72, 67, 13, 3, 2], [1, 3, 32, 61, 66, 53, 64, 65, 57, 66, 72, 57, 3, 72, 57, 66, 59, 67, 3, 65, 61, 3, 68, 70, 67, 68, 61, 67, 3, 55, 67, 55, 60, 57, 13, 3, 2], [1, 3, 42, 70, 61, 65, 57, 70, 67, 3, 56, 89, 62, 53, 65, 57, 3, 68, 70, 57, 59, 73, 66, 72, 53, 70, 72, 57, 3, 57, 71, 72, 67, 13, 3, 2]]\n"
     ]
    }
   ],
   "source": [
    "decoder_input = []\n",
    "for line in lines.tar:\n",
    "    temp_X = []\n",
    "    for w in line:\n",
    "        temp_X.append(tar_to_index[w])\n",
    "    decoder_input.append(temp_X)\n",
    "print(decoder_input[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 44, 57, 64, 64, 57, 66, 57, 3, 57, 71, 72, 57, 3, 58, 67, 70, 65, 73, 64, 53, 70, 61, 67, 11, 3, 68, 67, 70, 3, 58, 53, 74, 67, 70, 13, 3, 2], [3, 38, 64, 57, 66, 53, 3, 57, 64, 3, 54, 53, 64, 56, 57, 3, 55, 67, 66, 3, 53, 59, 73, 53, 13, 3, 2], [3, 32, 61, 66, 53, 64, 65, 57, 66, 72, 57, 3, 72, 57, 66, 59, 67, 3, 65, 61, 3, 68, 70, 67, 68, 61, 67, 3, 53, 73, 72, 67, 13, 3, 2], [3, 32, 61, 66, 53, 64, 65, 57, 66, 72, 57, 3, 72, 57, 66, 59, 67, 3, 65, 61, 3, 68, 70, 67, 68, 61, 67, 3, 55, 67, 55, 60, 57, 13, 3, 2], [3, 42, 70, 61, 65, 57, 70, 67, 3, 56, 89, 62, 53, 65, 57, 3, 68, 70, 57, 59, 73, 66, 72, 53, 70, 72, 57, 3, 57, 71, 72, 67, 13, 3, 2]]\n"
     ]
    }
   ],
   "source": [
    "decoder_target = []\n",
    "for line in lines.tar:\n",
    "    t = 0\n",
    "    temp_X = []\n",
    "    for w in line:\n",
    "        if t > 0 :\n",
    "            temp_X.append(tar_to_index[w])\n",
    "        t = t + 1\n",
    "    decoder_target.append(temp_X)\n",
    "print(decoder_target[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "79\n"
     ]
    }
   ],
   "source": [
    "max_src_len = max([len(line) for line in lines.src])\n",
    "max_tar_len = max([len(line) for line in lines.tar])\n",
    "print(max_src_len)\n",
    "print(max_tar_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "encoder_input = pad_sequences(encoder_input, maxlen=max_src_len, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen=max_tar_len, padding='post')\n",
    "decoder_target= pad_sequences(decoder_target, maxlen=max_tar_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "encoder_input = to_categorical(encoder_input)\n",
    "decoder_input = to_categorical(decoder_input)\n",
    "decoder_target = to_categorical(decoder_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0518 21:07:04.329751 15308 deprecation.py:506] From c:\\users\\yunja_kuj61s9\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "encoder_inputs = Input(shape=(None, src_vocab_size))\n",
    "encoder_lstm = LSTM(units=256, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, tar_vocab_size))\n",
    "decoder_lstm = LSTM(units=256, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _=decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "\n",
    "decoder_softmax_layer = Dense(tar_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0518 21:07:04.792513 15308 deprecation.py:323] From c:\\users\\yunja_kuj61s9\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 576s 14ms/sample - loss: 1.0937 - val_loss: 1.0106\n",
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 590s 15ms/sample - loss: 0.7374 - val_loss: 0.8519\n",
      "Epoch 3/20\n",
      "40000/40000 [==============================] - 602s 15ms/sample - loss: 0.6357 - val_loss: 0.7657\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 590s 15ms/sample - loss: 0.5750 - val_loss: 0.7093\n",
      "Epoch 5/20\n",
      "40000/40000 [==============================] - 591s 15ms/sample - loss: 0.5348 - val_loss: 0.6686\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 597s 15ms/sample - loss: 0.5053 - val_loss: 0.6423\n",
      "Epoch 7/20\n",
      "40000/40000 [==============================] - 585s 15ms/sample - loss: 0.4827 - val_loss: 0.6243\n",
      "Epoch 8/20\n",
      "40000/40000 [==============================] - 1374s 34ms/sample - loss: 0.4646 - val_loss: 0.6101\n",
      "Epoch 9/20\n",
      "40000/40000 [==============================] - 603s 15ms/sample - loss: 0.4492 - val_loss: 0.5954\n",
      "Epoch 10/20\n",
      "40000/40000 [==============================] - 600s 15ms/sample - loss: 0.4359 - val_loss: 0.5886\n",
      "Epoch 11/20\n",
      "40000/40000 [==============================] - 604s 15ms/sample - loss: 0.4243 - val_loss: 0.5790\n",
      "Epoch 12/20\n",
      "40000/40000 [==============================] - 601s 15ms/sample - loss: 0.4143 - val_loss: 0.5715\n",
      "Epoch 13/20\n",
      "40000/40000 [==============================] - 606s 15ms/sample - loss: 0.4053 - val_loss: 0.5669\n",
      "Epoch 14/20\n",
      "40000/40000 [==============================] - 630s 16ms/sample - loss: 0.3974 - val_loss: 0.5625\n",
      "Epoch 15/20\n",
      "40000/40000 [==============================] - 625s 16ms/sample - loss: 0.3901 - val_loss: 0.5609\n",
      "Epoch 16/20\n",
      "40000/40000 [==============================] - 612s 15ms/sample - loss: 0.3834 - val_loss: 0.5574\n",
      "Epoch 17/20\n",
      "40000/40000 [==============================] - 624s 16ms/sample - loss: 0.3771 - val_loss: 0.5537\n",
      "Epoch 18/20\n",
      "40000/40000 [==============================] - 651s 16ms/sample - loss: 0.3713 - val_loss: 0.5514\n",
      "Epoch 19/20\n",
      "40000/40000 [==============================] - 636s 16ms/sample - loss: 0.3661 - val_loss: 0.5526\n",
      "Epoch 20/20\n",
      "40000/40000 [==============================] - 622s 16ms/sample - loss: 0.3610 - val_loss: 0.5505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x235b8f57710>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[encoder_input, decoder_input], y=decoder_target, batch_size=64, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(inputs = encoder_inputs, outputs = encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(256,))\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, \n",
    "                                                 initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "decoder_model = Model(inputs = [decoder_inputs] + decoder_states_inputs, \n",
    "                      outputs = [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_src = dict((i,char) for char, i in src_to_index.items())\n",
    "index_to_tar = dict((i,char) for char, i in tar_to_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1,1,tar_vocab_size))\n",
    "    target_seq[0,0,tar_to_index['\\t']] = 1.\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "    \n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        \n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = index_to_tar[sampled_token_index]\n",
    "        \n",
    "        decoded_sentence += sampled_char\n",
    "        \n",
    "        if(sampled_char == '\\n' or len(decoded_sentence) > max_tar_len):\n",
    "            stop_condition = True\n",
    "            \n",
    "        target_seq = np.zeros((1,1,tar_vocab_size))\n",
    "        target_seq[0,0,sampled_token_index] = 1.\n",
    "        \n",
    "        states_value = [h, c]\n",
    "        \n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 문장: Tom has a problem.\n",
      "번역기가 번역한 문장:  Tom tiene un poco de agua. \n"
     ]
    }
   ],
   "source": [
    "print('입력 문장: ', end='')\n",
    "sent = [input()]\n",
    "input_sent = []\n",
    "for line in sent:\n",
    "    for w in line:\n",
    "        input_sent.append(src_to_index[w])\n",
    "input_sent = pad_sequences([input_sent], maxlen=max_src_len, padding='post')\n",
    "inputSent = to_categorical(input_sent, 84)\n",
    "decoded_sent = decode_sequence(inputSent)\n",
    "\n",
    "print('번역기가 번역한 문장:', decoded_sent[:len(decoded_sent)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
